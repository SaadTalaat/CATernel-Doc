28 November, 2012
Saad Talaat
===================

After the decision to change the CATernel design into microkernel, It became inevitable to implement early synchronization primitives and IPC scheme to convert kernel components into services.

The Basic synchronization primitive is considered the spinlock mentioned in the "Supporting SMP" section. This synchronization primitive is used in active synchronization in kernel only. other type of synchronization primitives is passive synchronization, this is the most used type which includes race conditions.

In the first prototype a minimal structure of the process descriptor was implemented which was suffcient for the first prototype phase. However, moving into multiprocessing environment and to be able to provide a concurrent backend even with a uniprocessor plus the nature of the kernel design obligated us to extend process structure. The old process descriptor structure contained :-
1- Process context
2- Process Id
3- Process Address space
4- Scheduling states
5- Pointers Proc List and running Procs LIFO

At this point also only three process states were supported
1- Process ready to run [RUNNABLE]
2- Process descriptor is undefined [EMPTY]
3- Process is not ready [NON_RUNNABLE]

Of course with such a structure processes are not able to support events, and doesn't even support them at all.

Supporting race conditions
==========================
A concurrent environment is unable to work in a consistent and proper way without race conditions of course. for a process/service to be able to process locking/unlocking events of a synchronization primitive it must either busy wait or block. However busy waiting is time wasting like in spinlocks and it probably would lead into deadlocks with prioritized processes design.
Blocking a process is simply done by two components, Scheduler and a waiting queue. Process simply waits on race conditions locks or IO events with either a state of those states [WAIT_INTERRUPTIBLE] or [WAIT_UNINTERRUPTIBLE].

However There's difference between Synchronization process communication, Inter-service/kernel communication and Standard InterProcess Communication.

Synchronization Communication
=============================
Race conditions are somehow an IPC mechanism from semaphores to message queues. However there's different implementations for such synchronization mechanisms and specially using waiting queues. for example Linux kernel makes no use of waiting queues but only timers, Mach makes use of a single waiting queue and SPARTAN makes use of a multiple waiting queues with also timers same as linux only renamed to timeouts.

At this point the [Timers] implementation seems convenient. Possible ways to implement a timer are by the RTC or APIC timer, of course with having a nearly SMP environment apply an RTC timer seems inconvenient. APIC timers however also has one-shot/periodic/tsc timers. a one-shot timer might be convient also. Another way implementing timers is by setting a timer relative to Scheduler timer interrupts with the timer interrupt as a one basic unit of timer.

A pre-mature implemenation for a synchronization based on timers and waiting queues is to update timers on each tick with extending implementation of timers via waiting queues and same for synchronization primitives.

Optimal Implementation
======================
When it came to implementation various designs and schemes came up to my mind (personally) not to mention other implementations adopted by other kernels.

*Semaphores*
implementing the semaphore's P&V with dijkstra's algorithm without using spinlocks isn't practical. for example to use a semaphore which only contains the integer value of the semaphore and ups and downs which directly puts an executing entity into a generic waiting process list makes it hard to determine which procs/threads are waiting for this specific resource/primitive and wake them up. a hack would be to make a list of pointers or indexes of thes procs into the generic waiting list in the semaphore itself, but this would cause contention over the generic waiting list, another memory unfriendly implementation is to make a waiting list per resource.
Within a Multiprocessor environment old irq_enable/disable won't work to keep the an up/down operation atomic. thus a spinlock implementation is a must. of course disabling all processors irqs is nonsense.

Case Studies
============

GNU Mach
--------
GNU Mach impelements wait queues implicitly into a thread structure, with only one type of waiting [THREAD_WAIT]. The thread state is changed into wait so the scheduler won't pick it the next time it is invoked. However such implementation is minimal compared to the Linux implementation.


Minix
--------
Minix implementation to IPC is rather complicated, actually very complicated. it doesn't make use of any processes blocking or suspention and ipc is done via a seperate server not as a global entity. This implementation is similar to the System V semaphores implementation. This implementation is for generic IPC purposes and Svr5 Standardization

Linux - POSIX
-------------
The way Linux implements locking and IPC waiting is by spinlocking using a unified locking way called ipc_lock. so the lock is being polled on, scheduler however makes use of this waiting into blocking a thread implicitly using the Linux waiting queues in the form of semaphore queues. However This implementation at ipc/sem.c is a System V semaphore which we don't really need at the moment. since it's for IPC Purposes not synchronization.
another implementation of the semaphore is used in kernel/semaphore explicitly makes use of waiting and task state.

SPARTAN
-------
the SPARTAN waiting queues are very similar if not identical to the linux waiting queues, however its semaphores makes use of waiting queue explicitly. Which makes the SPARTAN semaphores and ipc more effective and fast than any other.
